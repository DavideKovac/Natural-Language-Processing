#!/usr/bin/env python
# coding: utf-8

# # Natural Language Processing Project
#
# We will use the [Yelp Review Data Set from Kaggle](https://www.kaggle.com/c/yelp-recsys-2013).
# 
# Each observation in this dataset is a review of a particular business by a particular user.
# 
# The "stars" column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.
# 
# The "cool" column is the number of "cool" votes this review received from other Yelp users. 
# 
# All reviews start with 0 "cool" votes, and there is no limit to how many "cool" votes a review can receive. In other words, it is a rating of the review itself, not a rating of the business.
# 
# The "useful" and "funny" columns are similar to the "cool" column.

#Imports the libraries

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
sns.set_style('whitegrid')
get_ipython().run_line_magic('matplotlib', 'inline')


#Import the data

yelp=pd.read_csv('yelp.csv')


#Check the head, info , and describe methods on yelp.

yelp.head()

yelp.info

yelp.describe


#Create a new column called "text length" which is the number of words in the text column.

yelp['text lenght']=yelp['text'].apply(len)
yelp.head()


#Data Analysis
#FacetGrid from the seaborn library to create a grid of 5 histograms of text length based off of the star ratings.

g=sns.FacetGrid(yelp,col='stars')
g.map(sns.histplot,'text lenght')


#Boxplot of text length for each star category.

sns.boxplot(x='stars',y='text lenght',data=yelp)

#Countplot of the number of occurrences for each type of star rating.

sns.countplot(x='stars',data=yelp)

#Use groupby to get the mean values of the numerical columns

df_mean=yelp.groupby('stars').mean()
df_mean.head()


#Use the corr() method on that groupby dataframe to produce 

df_corr=df_mean.corr()
df_corr.head()


#Heatmap based off that .corr() dataframe

sns.heatmap(df_corr,cmap='coolwarm',annot=True)

#NLP Classification Task

#Create a yelp_class with the review that have 1 or 5 stars

yelp_class=yelp[(yelp['stars']==1)| (yelp['stars']==5)]
yelp_class.head()

#Create two objects X and y. X will be the 'text' column of yelp_class and y will be the 'stars' column of yelp_class.(Features and target/labels)

x=yelp_class['text']
y=yelp_class['stars']


#Import CountVectorizer and create a CountVectorizer object.

from sklearn.feature_extraction.text import CountVectorizer
bow_transform=CountVectorizer()

#Change the x value to trasformed version

x=bow_transform.fit_transform(x)


#Train test split

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test=train_test_split(x,y,test_size=0.3,random_state=101)


#Training the  Model

from sklearn.naive_bayes import MultinomialNB
sdm=MultinomialNB().fit(X_train,y_train)


#Predictions and Evaluations

pred=sdm.predict(X_test)
from sklearn.metrics import confusion_matrix,classification_report
print(confusion_matrix(y_test,pred))
print('\n')
print(classification_report(y_test,pred))

#Other NLP with Pipeline

from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.pipeline import Pipeline


#Create a pipeline with the following steps:CountVectorizer(), TfidfTransformer(),MultinomialNB()**
pip=Pipeline([
             ('bow',CountVectorizer()),
             ('tfidf',TfidfTransformer()),
             ('classifier',MultinomialNB()),
])


#Train test split

x=yelp_class['text']
y=yelp_class['stars']
X_train, X_test, y_train, y_test=train_test_split(x,y,test_size=0.3,random_state=101)


#Fit the model

pip.fit(X_train,y_train)


#Predictions and Evaluation

pred=pip.predict(X_test)

print(confusion_matrix(y_test,pred))
print('\n')
print(classification_report(y_test,pred))

#Comparing the two methods the first one was slight better
